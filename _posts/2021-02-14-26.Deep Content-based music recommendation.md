---
title: 26.[paper review] Deep Content-based music recommendation
categories: [RS]
tags: 
excerpt: Deep Content-based music recommendation
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# [ Recommender System ]

# 26. Deep Content-based music recommendation

( 참고 : Fastcampus 추천시스템 강의 )

<br>

## Abstract

- music recommendation에 대한 수요 증가 ( ex. Spotify... )
- Latent Factor Model을 사용한 recommendation
- Latent Factor
  - 사용자가 이 음악을 좋아할까? (X)-
  - **음악 자체의 data만을 사용 (O)**
- **Bag-of-words & Deep CNN**

- Semantic gap이 존재

  - Semantic gap ? 

    음악의 '오디오'만을 사용하여 추출하기 때문에, 메타 정보 (가수, 출시 년도) 등에 대해서는 파악 불가하다

    여기서 발생하게 되는 gap을 의미!

  

## 1. Introduction

Music Recommendation은 매우 복잡 ( 너무 다양한 장르! )

대부분의 추천은 **패턴**에 의존



Content-based music recommendation

- item과 item 사이의 similarity
- meta data 사용 ( 가수, 앨범, 발매 년도)
- BUT 단순한 추천 ( ex. 가수 기준으로만 추천 )



Collaborative Filtering

- 사용자/아이템 기반의 **neighborhood-based** 방법
- 사용자/아이템의 latent를 modeling하는 **model-based** 방법



Semantic gap in music

- 사용자의 이용 정보(=sparse data) 등과 다르게, **음성 신호는 노래만 있으면 얻어낼 수 있음**

  ( 보다 풍부한 정보 )

- 사용자 선호도에 영향을 끼치는 **음악의 특징 & 신호에는 Gap이 존재**

  ( High level properties (ex. 장르, 분위기, 가수의 유명도 등)은 음성신호에서 알아내기 어려움 )

- 음성신호를 가공한 MFCC를 사용



DeepCNN을 학습 & latent factor를 예측 $$\rightarrow$$ 이를 통해 semantic gap을 줄이고자!



## 2. Dataset

1,000,000개의 노래

- meta data
- audio features



## 3. Weighted Matrix Factorization

재생 횟수 $$r_{ui}$$ 

- $$r_{ui}$$ 가 높다 = 좋아하는 노래다\



두 가지의 variable

- 1) Preference variable : $$p_{u i}=I\left(r_{u i}>0\right)$$
  - 유저 $$u$$가 음악 $$i$$를 들었는지 여부
- 2) Confidence variable : $$c_{u i}=1+\alpha \log \left(1+\epsilon^{-1} r_{u i}\right)$$
  - preference에 대해 확신을 하는 정도
  - 재생 횟수 $$r_{ui}$$에 대한 함수 & 높을 수록 더 선호



최종적인 objective function

- $$\min _{x_{*}, y_{*}} \sum_{u, i} c_{u i}\left(p_{u i}-x_{u}^{T} y_{i}\right)^{2}+\lambda(\sum_{u} \mid \mid x_{u}\mid \mid^{2}+\sum_{i} \mid \mid y_{i}\mid \mid^{2})$$.



## 4. Predicting latent factors from music audio

Predicting latent factors = Regression with audio!

2가지 방법

- 1) Bag-of-words
- **2) Deep CNN**

vs

- WMF에서 얻은 latent factor vectors를 baseline으로



## 5. Bag-of-words Representation

step 1) Audio에서 MFCC를 추출 

- ( = 중요한 정보만 keep )

step 2) MFCC를 vector quantize ( with K-means clustering )

- $$N$$개의 feature vector $$x$$를 $$k$$개의 $$y$$ 로 

step 3) Bag-of-words representations

- 모든 노래의 count 횟수를 사용

step 4) Dimension reduction with PCA



## 6. Deep CNN

[ 학습 & 예측 과정 ]

step 1) Intermediate time-frequency representation을 모델의 input올

- 3초 단위로 sampling

step 2) consecutive window averaging으로 전체 Audio의 latent factor를 예측



Extraction & Pooling layer로 time-scale에서 작동...따라서 CNN도 음성에사용 OK



Loss Function 

- 방법 1) MSE

- 방법 2) WPE ( Weighted Prediction Error...WMF의 최적화 함수 ) 

  $$\min _{\theta} \sum_{u, i} c_{u i}\left(p_{u i}-x_{u}^{T} y_{u}^{\prime}\right)^{2}$$.



## 7. Latent Factor Prediction : Quantitative Evaluation

특이점 : (성능) CNN with MSE>  CNN with MSE

- WPE에는 가중치 O

- 따라서, 노래의 중요성/인기도가 비례하여 loss 에 반영됨

  이로 인해, 결국 인기 있는 노래에 대해서만 latent feature를 잘 학습하게 되는 문제가!

  

## 8. Latent Factor Prediction : Qualitative Evaluation

WMF의 추천 

- 특정 가수에 집중해서 추천

DeepCNN

- 다양하게 추천!



## 9. Conclusion

- Deep CNN을 사용하여 latent factor 예측
- 유명하지 않은 (새로운) 노래 추천에 Good
- 기존의 모델들보다 성능 Good
- Music Information Retrieval 분야에서의 효과 기대