
# Seq2Seq 구현

### ![image.png](attachment:image.png)


```python
import random
import tensorflow as tf
from konlpy.tag import Okt
```

## 1) Hyperparameter


```python
EPOCHS = 50
NUM_WORDS=2000
```

## 2) Modeling

>### 1. Encoder
- embedding : maximum word length : 2000 & 64 embedding nodes
- lstm : 512 nodes ( return_state = True : to get the Hidden & Cell state )
- no need of (predicted y) in LSTM ! will give (real y) as a input of next state


```python
class Encoder(tf.keras.Model):
    def __init__(self):
        super(Encoder,self).__init__()
        self.emb = tf.keras.layers.Embedding(NUM_WORDS,64) # maximum of 2000 words
        self.lstm = tf.keras.layers.LSTM(512,return_state=True)
    
    def call(self,x,training=False,mask=None):
        x = self.emb(x)
        _,h,c = self.lstm(x) # output of LSTM : Y, H(hidden state), C(cell state)
        return h,c
```

>###  2. Decoder
- embedding & LSTM & Dense
- Dense : give probability of 2000 words
- give output of lstm as a input of the next state


```python
class Decoder(tf.keras.Model):
    def __init__(self):
        super(Decoder,self).__init__()
        self.emb = tf.keras.layers.Embedding(NUM_WORDS,64)
        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)
        self.dense = tf.keras.layers.Dense(NUM_WORDS,activation='softmax') 
    
    def call(self,inputs,training=False, mask=None):
        x,h,c = inputs
        x = self.emb(x)
        x,h,c = self.lstm(x, initial_state=[h,c])
        return self.dense(x), h,c
```

>### 3. Seq2Seq


```python
class Seq2seq(tf.keras.Model):
    def __init__(self,sos,eos):
        super(Seq2seq,self).__init__()
        self.enc= Encoder()
        self.dec = Decoder()
        self.sos = sos
        self.eos = eos
    
    def call(self, inputs, training=False, mask=None):
        # (1) Training
        if training is True:
            x,y = inputs
            h,c = self.enc(x) # encode ( input : X / output : H(Hidden) & C(Cell) )
            y,_,_ = self.dec((y,h,c)) # decode ( input : previous actual Y, H, C / output : predicted Y )
            return y # final : return the predicted words!
        
        # (2) Testing
        else :
            x = inputs # no label data
            h,c = self.enc(x) # encode 
            y = tf.conver_to_tensor(self.sos) # initial y : sos
            y = tf.reshape(y,(1,1))            
            seq = tf.TensorArray(tf.int32, 64)
            
            for idx in tf.range(64):
                y,h,c = self.dec([y,h,c]) # input : y(previous prediction),embedded h&c
                                                    # output : y(Softmax result)
                y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)  # get the biggest prob
                y = tf.reshape(y,(1,1))
                seq = seq.write(idx,y)  # ex. (idx:5, result : Boy)
                if y==self.eos:
                    break
            return tf.reshape(seq.stack(), (1,64))
```

## 3) Train & Test function


```python
@tf.function
def train_step(model, inputs, labels, loss_object, optimizer, train_loss,train_accuracy):
    output_labels = labels[:,1:] # real answer (2,3,4..100)
    shifted_labels = labels[:,:-1] # give label as an input to next state (1,2,3...,99)
    
    with tf.GradientTape() as tape:
        # input variable : inputs(H,C) + shifted_labels(previous label)
        predictions = model([inputs, shifted_labels], training=True) 
        loss = loss_object(output_labels, predictions) # (real answer) VS (predicted answer)
    gradients = tape.gradient(loss, model.trainable_variables)
    
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    train_loss(loss)
    train_accuracy(output_labels, predictions)
    
@tf.function
def test_step(model,inputs):
    return model(inputs, training=False)
```

## 4) Final Dataset


```python
dataset_file = 'chatbot_data.csv'
okt = Okt()

## 1. preparing Q&A dataset
with open(dataset_file,'r',encoding="utf-8") as file:
    lines = file.readlines()
    seq = [' '.join(okt.morphs(line)) for line in lines] # 형태소 분석

questions = seq[::2] # even numbers 
answers = ['\t' + lines for lines in seq[1::2]]

num_samples = len(questions)
perm = list(range(num_samples)) # 
random.seed(0)
random.shuffle(perm)

train_q = list()
train_a = list()
test_q = list()
test_a = list()

for idx, qna in enumerate(zip(questions, answers)):
    q,a= qna
    # train_test split : (8 : 2)
    if perm[idx] > num_samples//5:
        train_q.append(q)
        train_a.append(a)
    else:
        test_q.append(q)
        test_a.append(a)

# 2. Tokenize ( word -> number )& filtering
tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS,
                                                 filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')
tokenizer.fit_on_texts(train_q+train_a) # fit tokenizer
train_q_seq = tokenizer.texts_to_sequences(train_q)
train_a_seq = tokenizer.texts_to_sequences(train_a)
test_q_seq = tokenizer.texts_to_sequences(test_q)
test_a_seq = tokenizer.texts_to_sequences(test_a)

# 3. Padding ( train : pre_pad, test : post_pad)
x_train = tf.keras.preprocessing.sequence.pad_sequences(train_q_seq,
                                                       value=0,padding='pre',maxlen=64)
y_train = tf.keras.preprocessing.sequence.pad_sequences(train_a_seq,
                                                       value=0,padding='post',maxlen=64)
x_test = tf.keras.preprocessing.sequence.pad_sequences(test_q_seq,
                                                       value=0,padding='pre',maxlen=64)
y_test = tf.keras.preprocessing.sequence.pad_sequences(test_a_seq,
                                                       value=0,padding='post',maxlen=64)

# 4. Final Dataset
train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(32).prefetch(1024)
test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(1).prefetch(1024)
```

## 5) Model, Losses, Optimizer


```python
model = Seq2seq(sos=tokenizer.word_index['\t'],
               eos=tokenizer.word_index['\n'])
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam()

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
```

## 6) Train


```python
for epoch in range(EPOCHS):
    # train in one epoch
    for seqs, labels in train_ds:
        train_step(model,seqs,labels,loss_object,optimizer, train_loss, train_accuracy)
        
    # result
    template = 'Epoch {}, Loss : {}, Accuracy : {}'
    if epoch%10==0:
        print(template.format(epoch+1,
                              train_loss.result(),
                              train_accuracy.result()*100))
    
    train_loss.reset_states()
    train_accuracy.reset_states()
```

    Epoch 1, Loss : 0.4995741844177246, Accuracy : 89.34902954101562
    Epoch 11, Loss : 0.41853445768356323, Accuracy : 92.2663803100586
    Epoch 21, Loss : 0.3441966474056244, Accuracy : 93.5553207397461
    


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-36-b29f3ddda517> in <module>
          2     # train in one epoch
          3     for seqs, labels in train_ds:
    ----> 4         train_step(model,seqs,labels,loss_object,optimizer, train_loss, train_accuracy)
          5 
          6     # result
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
        455 
        456     tracing_count = self._get_tracing_count()
    --> 457     result = self._call(*args, **kwds)
        458     if tracing_count == self._get_tracing_count():
        459       self._call_counter.called_without_tracing()
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
        485       # In this case we have created variables on the first call, so we run the
        486       # defunned version which is guaranteed to never create variables.
    --> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        488     elif self._stateful_fn is not None:
        489       # Release the lock early so that multiple threads can perform the call
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
       1821     """Calls a graph function specialized to the inputs."""
       1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       1824 
       1825   @property
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
       1139          if isinstance(t, (ops.Tensor,
       1140                            resource_variable_ops.BaseResourceVariable))),
    -> 1141         self.captured_inputs)
       1142 
       1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1222     if executing_eagerly:
       1223       flat_outputs = forward_function.call(
    -> 1224           ctx, args, cancellation_manager=cancellation_manager)
       1225     else:
       1226       gradient_name = self._delayed_rewrite_functions.register()
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
        509               inputs=args,
        510               attrs=("executor_type", executor_type, "config_proto", config),
    --> 511               ctx=ctx)
        512         else:
        513           outputs = execute.execute_with_cancellation(
    

    ~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         59     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,
         60                                                op_name, inputs, attrs,
    ---> 61                                                num_outputs)
         62   except core._NotOkStatusException as e:
         63     if name is not None:
    

    KeyboardInterrupt: 


## 7) Test


```python
for test_seq, test_labels in test_ds:
    pred = test_step(model, test_seq) # model & x input
    question_text = tokenizer.sequences_to_texts(test_seq.numpy())
    real_text = tokenizer.sequences_to_texts(test_labels.numpy())
    pred_text = tokenizer.sequences_to_texts(pred.numpy())
    print('_________________________________')
    print('question: ', question_text)
    print('real answer: ', real_text)
    print('predicted answer: ', pred_text)
```
