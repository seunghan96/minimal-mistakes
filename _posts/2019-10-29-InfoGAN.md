---
title: InfoGAN (Interpretable Representation Learning by Information Maximizing GAN)
categories: [DL,GAN]
tags: [Deep Learning, InfoGAN]
excerpt: Interpretable Representation Learning by Information Maximizing GAN
---

# InfoGAN 
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

## 1. Introduction

지금까지 봐왔던 GAN모델들은, 이미지가 주어졌을 때, 해당 이미지의 latent representation을 찾아내어 해당 이미지를 다시 복원할 수 있는 것에 초점을 맞췄다. (그래서 Loss Function들도 주로 'fake image'가 원본 이미지와 얼마나 유사한지를 기준으로 잡았었다). 하지만 앞으로 살펴볼 모델들은, 단순히 원본을 복원하는 것을 넘어서, 내가 원하는 대로 사진의 특성을 설정할수 있다는 점에서 보다 뛰어나다고 할 수 있다. 예를 들어, 사람의 얼굴 image를 input으로 받으면, 그 사진에서 "눈썹 모양"을 의미하는 latent vector, "입의 모양"을 의미하는 latent vector 등, input으로 들어온 사진을 **분해하여** 그에 해당하는 각각의 vector를 학습한다. 그 중 대표적인 InfoGAN과 StackedGAN에 대해서 살펴볼 것이고, 이번 포스트에서는 **InfoGAN**에 대해서 알아볼 것이다.

<br>

<img src="https://image.slidesharecdn.com/infogan-190408061341/95/infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets-14-638.jpg?cb=1554704301" width="850" /> 

https://image.slidesharecdn.com/infogan-190408061341/95/infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets-14-638.jpg?cb=1554704301



## 2. 분해된 표현의 GAN

우리는 여태까지 input image의 잠재 벡터(latent vector)를 찾아냈었다. 하지만 앞으로는 이 잠재벡터를, "해석 가능한 latent vector"와 "그렇지 못한 vector (noise)"로 나누어서 생각할 것이다.

모든 latent vector를 **Z**로 표현하고, 그 중 

- 설명가능한 latent vector는 (1) **c**
- noise vector는 (2) **z**

로 표현하겠다.



여기서 추가할 가정은, "모든 설명가능한 latent vector c는 독립적이다"라는 것이다. 식으로 표현하면 다음과 같다.

$$p(c_1,c_2,..,c_L) = \prod_{i=1}^{L}p(c_i)$$

<br>



## 3. InfoGAN

InfoGAN의 핵심은 무엇일까? 직관적으로 생각해보면, 모든 latent vector **Z**에서 최대한 모든 벡터들을 설명가능하게끔 하는 것이다. 즉, 다르게 말하면 **Z** 중 **c**의 비중은 높고, **z**의 비중은 낮게 하는 것이다.

이를 다르게 표현하면, latent vector **c**와 , z와 c를 넣어서 생성된 image인 **G(z,c)**의 상호 정보를 최대화하는 것이라고 할 수 있다. 이 '상호 정보'의 정도를 다음과 같이 표현한다.

$$I(c ; G(z,c))$$ ( = $$ I(c; G(Z)))$$  )

<br>

위 정보는 다음과 같은 식으로 표현할 수 있다.

$$I(c ; G(z,c))$$  = $$H(c) - H(c \mid G(z,c)))$$

위의 $$H$$함수는 entropy값을 의미한다 ( entropy는 불확실성을 측정하는 지표로, 이 값이 높으면 '확률이 낮다, 즉 불확실하다' 를 의미한다 )



우리는 위 식 $$I(c;G(z,c))$$ 를 높이기 위해 $$H(c \mid  G(z,c)))$$ 값을 최소화 하면 된다 ( $$H(c)$$는 상수 취급한다 ) 

더 나아가기에 앞서서 Entropy에 대해서 알아보자.



### Entropy

 모든 사건 정보량의 기대값을 뜻함 ( 전체 사건의 확률분포의 불확실성의 양 )

$$H(P) = H(x) = E_{X \sim P}[I(x)] = E_{X\sim P}[-logP(x)] = -\sum_x P(x)logP(x)$$

$$H(P,Q) = E_{X\sim P}[-logQ(x)] = -\sum_x P(x) logQ(x)$$



KL-Divergence에서도 위 두 식을 통해 나타낼 수 있다.

$$\begin{align*}
   D_{KL}(P\mid \mid Q) &= -\sum_x P(x) log(\frac{Q(X)}{P(X)})\\
   &=-\sum_x P(x)\{logQ(x) - logP(x)) \}\\
   &=-\sum_x \{P(x)logQ(x) - P(x)logP(x)) \}\\ 
   &=-\sum_x P(x)logQ(x) + \sum_x P(x)logP(x)\\ 
   &=H(P,Q) - H(P)
\end{align*}$$

<br>

Conditional Entropy는 다음과 같이 표현할 수 있다.

$$\begin{align*}
H(Y\mid X) &= \sum_{x,y}p(x,y)log(\frac{p(x)}{p(x,y)})\\
&=-\sum_{x,y}p(x,y)log(p(x,y)) + \sum_{x,y}p(x,y)log(p(x))\\
&= H(X,Y) + \sum_{x}p(x)(logp(x)))\\
&= H(X,Y) - H(X)
\end{align*}$$

<br>

<br>

다시 돌아와서, $$H(c \mid  G(z,c)))$$를 최소화해보자.

이 식은, 위에서 배운 Entropy와 KL-Divergence를 사용하면 다음과 같이 나타낼 수 있다.

$$H(c \mid G(z,c)) = H(G(z,c),c) - H(G(z,c)) = D_{KL}(G(z,c)\mid\mid c)$$



따라서, 우리는 다음과 같은 Lower Bound를 추정할 수 있다.

$$I(c; G(z,c)) \geq L(G,Q) = E_{c \sim P(c), x \sim G(z,c)}[logQ(c\mid x)] + H(c) $$

<br>

<br>

## 4. Loss Function of InfoGAN

**GAN**

- Discriminator의 Loss Function : $$L^{(D)} = - E_{x \sim P_{data}}logD(x) - E_z log(1-D(G(z))) $$
- Generator의 Loss Function : $$L^{(G)} = - E_zlogD(G(z))$$

<br>

**InfoGAN**

- Discriminator의 Loss Function : $$L^{(D)} = - E_{x \sim P_{data}}logD(x) - E_z log(1-D(G(z))) - \lambda I(c;G(z,c))$$
- Generator의 Loss Function : $$L^{(G)} = - E_zlogD(G(z)) - \lambda I(c;G(z,c))$$

각각의 Loss Function에 $$I(c;G(z,c))$$ 와, 이를 조절해주는 parameter인 $$\lambda$$가 들어가는 것을 확인할 수 있다.

<br>

<br>

## 5. Summary

지금까지 배운 내용을 다음 사진 한 장으로 정리할 수 있다.

<img src="https://greeksharifa.github.io/public/img/2019-03-20-advanced-GANs/infoGAN1.png" width="550" /> 

https://greeksharifa.github.io/public/img/2019-03-20-advanced-GANs/infoGAN1.png

<br>

위 그림에서 Q는, 상호정보 손실을 최소화 하기 위해서 훈련이 이루어진다. 이를 통해 새로 생성되는 c'과 c의 cross entropy를 줄여나가는 방향으로 update가 이루어진다.





















## 2. Various Distance

GAN을 훈련시키기 위해, 우리는 Generator가 만들어낸 가짜 정답과 진짜 정답, 이 둘 간의 차이를 최소화한다. 여기서 즉, 우리는 Generator가 만들어낸 가짜 데이터의 분포$$p_g$$를 진짜 데이터의 분포인 $$p_{data}$$와 유사하게 만들기 위해, 이 두 분포간의 거리를 minimize한다. 여기서 '거리'를 어떻게 정의하냐에 따라 GAN의 성능은 달라진다.



두 분포 사이의 거리를 나타내는 대표적인 지표로는 다음과 같이 3가지가 있다.

( 엄밀히 말하면, (1)KL-Divergence는 '거리'라고 할 수 없다. 거리는 symmetric해야 하지만, KL-Divergence는 해당 조건을 충족시키지 못한다. 하지만 두 분포 사이의 차이를 나타낸다는 점에서 여기서 함께 설명하겠다 )

### (1) KL Divergence ( Kullback-Leibler Divergence)

$$D_{KL} (p_{data} \mid\mid p_{g} ) = E_{x \sim p_{data}}log\frac{p_{data}(x)}{p_{g}(x)}$$

- symmetric하지 않다 ( $$D_{KL} (p_{data} \mid\mid p_{g} ) $$ $$\neq$$ $$D_{KL} (p_{g} \mid\mid p_{data} ) $$)

<br>

### (2) JS Divergence ( Jensen-Shannon Divergence)

$$D_{JS} (p_{data} \mid\mid p_{g} ) = \frac{1}{2}E_{x \sim p_{data}}log\frac{p_{data}(x)}{\frac{p_{data}(x) + p_{g}(x)}{2}} + \frac{1}{2}E_{x \sim p_{g}}log\frac{p_{g}(x)}{\frac{p_{data}(x) + p_{g}(x)}{2}}$$

<br>

### (3) EMD ( Earth-Mover Distance )

- also called "Wesserstein Distance"

$$W(p_{data},p_g) = \underset{\gamma \in \prod (p_{data},p_g)}{inf}E_{(x,y)\sim \gamma}[\mid\mid x-y \mid\mid]$$

<br>

여기서 (3) EMD를 직관적으로 해석하자면, 이는 분포 $$p_{data}$$ 를 분포 $$p_{g}$$와 같게 만들기 위해 "얼마나 많은 질량"을 "얼만큼의 거리"를 움직여야하는가?를 의미한다.

- 얼마나 많은 질량 : $$\gamma (x,y)$$
- 얼만큼의 거리 : $$ d = \mid\mid x-y\mid\mid$$

<br>



## 3. Loss Function of WGAN

우리는 이전 포스트에서 GAN의 Discriminator의 Loss function이 다음과 같음을 확인했었다.

$$ L^{(D)}$$ = $$ -E_{x \sim P_{data}}logD(x)$$ $$ -E_{z}log(1-D(G(z)))$$



위 식에서 $$z$$ (노이즈)에서 샘플링 하는 대신, Generator의 분포에서 샘플링을하면 위 식을 다음과 같이 표현할 수 있다.

$$ L^{(D)}$$ = $$ -E_{x \sim P_{data}}logD(x)$$ $$ -E_{p_g}log(1-D(x))$$

<br>

위 식을 정리하면 다음과 같다.

$$ L^{(D)} = - \int_{x} p_{data}(x) logD(x)dx - \int_{x}p_g(x)log(1-D(x))dx$$

$$ = -\int _{x} (p_{data}logD(x) + p_g(x)log(1-D(x)))dx$$

<br>

 이 식을 D(x)에 관해 미분하여 최적의 Discriminator를 구하면, 다음과 같이 나오게 된다.

$$ D^*(x) = \frac{p_{data}}{p_{data} + p_g}$$

<br>

이것을 대입하고 정리하면 다음과 같이 나온다.

$$\begin{align*}
   L^{(D^{*})} &= - E_{x \sim p_{data}}log\frac{p_{data}}{p_{data}+p_{g}} - E_{x \sim p_{g}}log[ 1- \frac{p_{data}} {p_{data}+p_{g}}] \\
&= - E_{x \sim p_{data}}log\frac{p_{data}}{p_{data}+p_{g}} - E_{x \sim p_{g}}log[\frac{p_{g}}{p_{data}+p_{g}}] \\
&= 2log2 - D_{KL}[p_{data} \mid \mid \frac{p_{data} + p_{g}}{2}] - D_{KL}[p_{g} \mid \mid \frac{p_{data} + p_{g}}{2}]\\
&= 2log2 - 2D_{JS}(p_{data} \mid \mid p_{g}) \\
\end{align*}$$

<br>

즉,  $$ L^{(D^{*})}$$ 를 최소화하는 것은 JS Divergence를 최대화 하는 것과 똑같다.

( Discriminator 입장에서는 두 분포가 최대한 다르게끔 인식되도록 노력한다! )

<br>

$$ D^*(x) = \frac{p_{data}}{p_{data} + p_g}$$ 식을 생각하면, 최적의 Discriminator는 $$ D^*(x) = 0.5 $$ 이다.

하지만 문제점이 있다. 만약 두 분포 $$p_{data}$$와$$p_g$$가 서로 겹치는 영역이 없으면, 학습 과정에서 수렴하지 않게 될 것이다.



## (1) Wesserstein Distance의 필요성

위에서 말했 듯, $$p_{data}$$와 $$p_g$$가 겹치지 않으면 수렴하지 않는 문제가 발생한다고 했다. 다음의 두 분포 예시를 통해 확인해보자.

- $$p_{data} = (x,y)$$,  $$x=0, y \sim U(0,1)$$
- $$p_g = (x,y)$$, $$ x=\theta, y\sim U(0,1)$$

<br>

위와 같은 두 분포가 주어졌을 때, 3가지 지표 (KL-Divergence, JS-Divergence, Wesserstein Distance)를 구하면 다음과 같다.

- $$D_{KL} (p_g \mid\mid p_data)$$ = $$\sum 1 log \frac{1}{0}$$ = $$+ \infty $$
- $$D_{JS}(p_{data} \mid \mid p_{g})$$ = $$\frac{1}{2}\sum 1 log \frac {1}{0.5} + \frac{1}{2}\sum 1 log \frac {1}{0.5} = log2 $$
- $$W(p_{data},p_{g})$$ = $$\mid \theta \mid $$

$$D_{KL}$$은 무한대로 가고, $$D_{JS}$$는 상수형태가 되어버린다. 따라서 다음과 같이 두개의 분포가 겹치는 경우에는, (안정성 측면에 있어서) $$W$$ 가 낫다고 할 수 있다.

<br>

## (2) Wesserstein Distance (EMD)

우리는 $$p_{data}$$ 와 $$p_g$$의 결합분포의 전체 집합인 $$\prod (p_{data},p_{g})$$ 를 전부 활용하기 사실상 힘들다. 그래서 Kantorovich-Rubinstein Duality를 사용하여 다음과 같이 나타낼 수 있다.



( 아래에서 $$P_r$$는 real data, $$P_\theta$$는 fake data이다 ) <img src="https://image.slidesharecdn.com/wgangp-170529050013/95/nthu-ai-reading-group-improved-training-of-wasserstein-gans-10-638.jpg?cb=1496049172" width="900" /> 

https://image.slidesharecdn.com/wgangp-170529050013/95/nthu-ai-reading-group-improved-training-of-wasserstein-gans-10-638.jpg?cb=1496049172



**K-Lipschitz Constratint** :

$$\mid f(x_1) - f(x_2) \mid \leq K \mid x_1 - x_2 \mid $$

<br>

식은 복잡하지만, 쉽게 생각해보자. Discriminator의 목적인 "진짜는 맞게(1 로) 분류", "가짜는 틀리게(0으로) 분류"하기 위해서, $$EMD(P_r,P_\theta)$$식의 구성 요소인 $$E_{x \sim P_r} f(x)$$는 크게, $$E_{x \sim P_\theta} f(x)$$는 작아져야 한다.

이를 활용하여, W를 정리하면 다음과 같다.

$$\begin{align*}
   W(p_{data}, p_g) &= \underset{w \in W}{max} E_{x \sim p_{data}}[f_{w}(x)] - E_{x \sim p_{g}}[f_{w}(x)]\\
   &= \underset{w \in W}{max} E_{x \sim p_{data}}[D_{w}(x)] - E_{z}[D_{w}(G(z))]\\
\end{align*}$$

이제 이것을 우리는 새로운 Loss Function으로 사용할 것이고, 이것이 바로 **WGAN**이다.

<br>

## (3) Summary of Loss Function

정리하면, Discriminator와 Generator의 Loss Function은 다음과 같다.



**Discriminator**

$$L^{(D)}= - E_{x\sim p_data}D_w(x) + E_z D_w(G(z))$$



**Generator**

$$ L^{(G)}= - E_z D_w(G(z)) $$

<br>



## 4. Algorithms of WGAN

- Until $$\theta$$  converges..

  

  **[ Discriminator ]**

  - for t=1,...$$n_{critic}$$  ( $$n_{critic}$$ : Generator가 1회 반복하는 동안 Discriminator가 반복하는 횟수)
    - $$\{x^{(i)}\}_{i=1}^m \sim p_{data}$$ 샘플링 ( m : batch size )  
    - $$\{z^{(i)}\}_{i=1}^m \sim p_{z}$$ 샘플링
    - caculcate gradient of Discriminator
    - update ( $$w \leftarrow w - \alpha \times RMSProp(w,g_w)$$ ) 
      ( WGAN에서는 Adam보다 RMS Prop을 사용하는 것이 더 안정적이라고 함 )
    - constraint on w ( $$ w \leftarrow clip(w,-c,c)$$ )

  - end for
    

  **[ Generator ]**

  - $$ \{z^{(i)}\}_{i=1}^m \sim p_{z} $$ 샘플링
  - caculcate gradient of Generator
  - update ( $$\theta \leftarrow \theta - \alpha \times RMSProp(\theta,G_{\theta})$$)
    

- end while

<br>



## 5. GAN vs WGAN

<img src="https://miro.medium.com/max/3136/1*5jF5gbIDwU6k9m1ILl0Utg.jpeg" width="950" /> 

https://miro.medium.com/max/3136/
