---
title: 2.EM algorithm (1)
categories: [EM Algorithm]
tags: [Bayesian,Statistics]
excerpt: Jensen's Inequality / KL-divergence / EM algorithm example
---

# 2. EM Algorithm (1)
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

There are two important concepts that you have to know, before knowing about EM Algorithm. They are 1. Jensen's inequality & 2. KL-divergence.

## (1) Jensen's inequality & KL-divergence

#### [ Jensen's inequality ]
- convex / concave
- relates the value of a convex/convex function of an integral to the integral of the convex/concave function
<br>
in the case of concave function..
<br>

If <a href="https://www.codecogs.com/eqnedit.php?latex=f(\alpha&space;a&space;&plus;&space;(1-\alpha)b)&space;\geq&space;\alpha&space;f(a)&space;&plus;&space;(1-\alpha)f(b)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(\alpha&space;a&space;&plus;&space;(1-\alpha)b)&space;\geq&space;\alpha&space;f(a)&space;&plus;&space;(1-\alpha)f(b)" title="f(\alpha a + (1-\alpha)b) \geq \alpha f(a) + (1-\alpha)f(b)" /></a>
<br>

Then Jensen's inequality is <a href="https://www.codecogs.com/eqnedit.php?latex=f(E_{p(t)}t)\geq&space;E_{p(t)}f(t)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(E_{p(t)}t)\geq&space;E_{p(t)}f(t)" title="f(E_{p(t)}t)\geq E_{p(t)}f(t)" /></a>
<br>

( a, b is a any two data point. alpha is a weight between 0 and 1 )
<br>
<br>
<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSjRIhCTLP24BF3xD5LKRsG5Lff15ue6KjtU9gA0cSEhJTYTlQV" width="550" /> <br>
https://encrypted-tbn0.gstatic.com/
<br>
<br>

#### [ KL-divergence ]
 KL-divergence( Kullbackâ€“Leibler divergence), which is also called relative entropy, is a measure of how one probability distribution is different from another probability distribution. 
<br>

For a discrete probability distribution, the KL-divergence of Q from P is
<br>

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4958785faae58310ca5ab69de1310e3aafd12b32" width="300" /> <br>
<br>

and for a continuous case, it is
<br>
<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/756dd25036c5da76a59e58a001f3196e059f537d" width="300" /> <br>
<br>

<img src="https://cs-cheatsheet.readthedocs.io/en/latest/_images/kl_divergence.png" width="550" /> <br>
https://cs-cheatsheet.readthedocs.io/en/latest/_images/kl_divergence.png
<br>

The three properties of KL-divergence are
<br>
1. KL(p|q) is not always same with KL(q|p)
2. KL(p|p) = 0
3. KL(p|q) is always more or equal to 0
<br>
<br>

## (2) EM algorithm 

( EM : Expectation-Maximization )

EM algorithm is one way of finding MLE in a probabilistic model which has latent variable. Before talking about this algorithm in detail, I'll start with an example. 



### example )

Remember soft clustering using GMM in the previous post? ( [https://seunghan96.github.io/em%20algorithm/8.-em-Latent_Variable_Models/](https://seunghan96.github.io/em algorithm/8.-em-Latent_Variable_Models/))

We had three mixture of Gaussian distribution ( 3 clusters ). We wanted to find the density of each data point ( $$ = p(X \mid \theta)$$ ) I told you that I will find this solution with EM algorithm, and I'm going to talk about that now. ( since now you know what Jensen's Inequality & KL-divergence are ). 

We take logarithm of the likelihood ( $$ = p(X \mid \theta)$$ ) for easier calculation. Then using Jensen's Inequality, we can make the expression like below.
<br>
<br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;logp(X|\theta)&space;&=&space;\sum_{i=1}^{N}logp(x_i|\theta)&space;\\&space;&=&space;\sum_{i=1}^{N}log&space;\sum_{c=1}^{3}\frac{q(t_i=c)}{q(t_i=c)}p(x_i,t_i=c|\theta)\\&space;&\geq&space;\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\&space;&=L(\theta,q)&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;logp(X|\theta)&space;&=&space;\sum_{i=1}^{N}logp(x_i|\theta)&space;\\&space;&=&space;\sum_{i=1}^{N}log&space;\sum_{c=1}^{3}\frac{q(t_i=c)}{q(t_i=c)}p(x_i,t_i=c|\theta)\\&space;&\geq&space;\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\&space;&=L(\theta,q)&space;\end{align*}" title="\begin{align*} logp(X|\theta) &= \sum_{i=1}^{N}logp(x_i|\theta) \\ &= \sum_{i=1}^{N}log \sum_{c=1}^{3}\frac{q(t_i=c)}{q(t_i=c)}p(x_i,t_i=c|\theta)\\ &\geq \sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\ &=L(\theta,q) \end{align*}" /></a>
<br>

#### [ Interpretation ]
We built a lower bound by using Jensen's Inequality, which is expressed as $$L(\theta,q)$$. Now, we are going to maximize this. Instead of directly maximizing the likelihood, we can maximize the lower bound instead to find the value of $$log p(X \mid \theta)$$. But we will not only use one lower bound. Instead, we can use a family of lower bounds, and choose the one that suits best at each iteration. Look at the picture below, and you will understand what I mean.
<br>

<img src="https://people.duke.edu/~ccc14/sta-663/_images/EMAlgorithm_19_0.png" width="450" /> <br>
https://people.duke.edu/~ccc14/sta-663/
<br>

The best lower bound among the lower bound family is chosen with the following expression. ( The best possible bound is when $$log\;p(X\mid \theta)$$ = $$L(\theta,q)$$ )
<br>
<br>
<a href="https://www.codecogs.com/eqnedit.php?latex=logp(X|\theta)\geq&space;L(\theta,q)&space;\;\;&space;for&space;\;&space;any&space;\;&space;q" target="_blank"><img src="https://latex.codecogs.com/gif.latex?logp(X|\theta)\geq&space;L(\theta,q)&space;\;\;&space;for&space;\;&space;any&space;\;&space;q" title="logp(X|\theta)\geq L(\theta,q) \;\; for \; any \; q" /></a>
<br>
<br>
<a href="https://www.codecogs.com/eqnedit.php?latex=q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" title="q^{k+1} = \underset{q}{argmax}L(\theta^k,q)" /></a>
<br>
<br>

That's all! Quite Simple! 

In short, all we have to do is maximizing the lower bound. So how do we maximize it? We do it iteratively (E-step & M-step). First, we fix $$\theta$$, and maximize the lower bound with respect to $$q$$. Then, we fix $$q$$, and do the same thing with respect to $$\theta$$. No you have seen how EM algorithm is applied to GMM.



#### Algorithm Summary
- E-step : fix $$\theta$$, maximize the lower bound with respect to q <br> <br>
<a href="https://www.codecogs.com/eqnedit.php?latex=q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" title="q^{k+1} = \underset{q}{argmax}L(\theta^k,q)" /></a>
- M-step : fix $$q$$, maximize the lower bound with respect to theta <br> <br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}L(\theta,q^{k&plus;1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}L(\theta,q^{k&plus;1})" title="\theta^{k+1} = \underset{\theta}{argmax}L(\theta,q^{k+1})" /></a>

In the next post, I'll tell you more about EM algorithm in detail.