---
title: 15.(nlp) CNN for NLP
categories: [DL,NLP]
tags: [Deep Learning, NLP]
excerpt: CNN for NLP
---

# CNN for NLP

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

( 참고 : "딥러닝을 이용한 자연어 처리 입문" (https://wikidocs.net/book/2155) )

<br>

# 1. Introduction

우리에게 CNN은 image 처리로만 익숙하다. 하지만 CNN은 nlp에서도 사용될 수 있다.

이번 포스트에서는, nlp에서 1D CNN이 어떻게 사용되는지 살펴볼 것이다.

<br>

우선, 아래와 같은 행렬을 생각해보자.

- $n$은 문장의 길이
- $k$는 embedding 차원

<img src="https://wikidocs.net/images/page/80437/sentence_matrix.PNG" width="200" />.

<br>

# 2. 1D CNN for NLP

CNN의 kernel 너비는, embedding 차원인 $k$와 동일하게 설정된다. (따라서, 일반적으로 kernel의 "높이"를 kernel size라고 부른다. )

- ex) kernel size=2

  <img src="https://wikidocs.net/images/page/80437/1d_cnn.PNG" width="300" />.

<br>

아래의 그림을 통해, 어떠한 과정으로 convolution이 이루어지는지를 쉽게 이해할 수 있다.

<img src="https://wikidocs.net/images/page/80437/%EB%84%A4%EB%B2%88%EC%A7%B8%EC%8A%A4%ED%85%9D.PNG" width="600" />.

<br>

어떻게 적용이 되는지는 쉽게 이해가 갈 것이다. 그렇다면, kernel size가 가지는 의미는 무엇일까?

이는, "참고하는 단어의 범위"로 생각할 수 있다. 즉, n-gram의 "n"으로 생각하면 된다.

아래의 그림은, kernel size가 3인 CNN으로, tri-gram이라고 생각할 수 있다.

<img src="https://wikidocs.net/images/page/80437/%EC%BB%A4%EB%84%903.PNG" width="400" />.

<br>

# 3. Max-Pooling

CNN에서의 Maxpooling과 동일하다.

아래의 그림은, 2개의 kernel ( 각각 kernel-size=2 ,  kernel-size=3  )로 부터 생성된 vector에서 Maxpooling을 한 결과다.

<img src="https://wikidocs.net/images/page/80437/%EB%A7%A5%EC%8A%A4%ED%92%80%EB%A7%81.PNG" width="600" />.

<br>

# 4. Architecture

위의 1D CNN과 Maxpooling을 결합하여 생성된 최종적인 Neural Net를 도식화 하면 아래와 같다.



<img src="https://wikidocs.net/images/page/80437/conv1d.PNG" width="400" />.



