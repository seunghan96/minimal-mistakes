---
title: 3.EM algorithm (2)
categories: [EM Algorithm]
tags: [Bayesian,Statistics]
excerpt: E-step / M-step
---

# 3. EM Algorithm (2)
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

We have seen that EM algorithm consists of two parts.
<br>

<img src="https://stillbreeze.github.io/images/em.jpg" width="550" /> <br>
https://stillbreeze.github.io/images/em.jpg
<br>

- E-step : fix $$\theta$$, maximize the lower bound with respect to $$q$$<br> <br>
<a href="https://www.codecogs.com/eqnedit.php?latex=q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q^{k&plus;1}&space;=&space;\underset{q}{argmax}L(\theta^k,q)" title="q^{k+1} = \underset{q}{argmax}L(\theta^k,q)" /></a>

- M-step : fix $$q$$, maximize the lower bound with respect to $$\theta$$ <br> <br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}L(\theta,q^{k&plus;1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}L(\theta,q^{k&plus;1})" title="\theta^{k+1} = \underset{\theta}{argmax}L(\theta,q^{k+1})" /></a>

Let's talk about each step more in detail.
<br>
<br>

## (1) E-step (Expectation)
It tries to maximize the lower bound with respect to $$q$$ ( while fixing $$\theta$$ ). That is same as minimizing the "gap between lower bound and log likelihood". The gap between these two can be expressed as a 'KL-divergence'.
<br>
( use the same example(GMM with three mixtures) )

$$\begin{align*} GAP &= logp(X|\theta)-L(\theta,q) \\ &= \sum_{i=1}^{N}logp(X_i|\theta)-\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{p(X_i,t_i=c|\theta)}{q(t_i=c)}\\ &= \sum_{i=1}^{N}(logp(X_i|\theta)\sum_{c=1}^{3}q(t_i=c)-\sum_{c=1}^{3}q(t_i=c)log\frac{p(X_i,t_i=c|\theta)}{q(t_i=c)}\\ &=\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)(logp(X_i|\theta)-log\frac{p(X_i,t_i=c|\theta)}{q(t_i=c)})\\ &=\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{p(X_i|\theta)q(t_i=c)}{p(X_i,t_i=c|\theta)} \\ &=\sum_{i=1}^{N}\sum_{c=1}^{3}q(t_i=c)log\frac{q(t_i=c)}{p(t_i=c|X_i,\theta)}\\ &=KL(q(t_i)||p(t_i=c \mid X_i,\theta))) \end{align*}$$

<br>

So, to maximize the lower bound, we minimize the KL-divergence. And to minimize the KL-divergence, we have to set $$q(t_i) = p(t_i = c \mid X_i,\theta)$$



General Expression : <a href="https://www.codecogs.com/eqnedit.php?latex=q^{k&plus;1}(t_i)&space;=&space;p(t_i|x_i,\theta^k)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q^{k&plus;1}(t_i)&space;=&space;p(t_i|x_i,\theta^k)" title="q^{k+1}(t_i) = p(t_i|x_i,\theta^k)" /></a>

<br>

## (2) M-step (Maximization)
On M-step, we want to maximize this lower bound with respect to $$\theta$$. It can be expressed as below. <br>
<br>

( use the same example(GMM with three mixtures) )

<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;L(\theta,q)&=\sum_{i}\sum_{c}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\&space;&=\sum_{i}\sum_{c}q(t_i=c)logp(x_i,t_i=c|\theta)&space;-&space;\sum_{i}\sum_{c}q(t_i=c)logq(t_i=c)\\&space;&=E_qlogp(X,T|\theta)&space;&plus;&space;const&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;L(\theta,q)&=\sum_{i}\sum_{c}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\&space;&=\sum_{i}\sum_{c}q(t_i=c)logp(x_i,t_i=c|\theta)&space;-&space;\sum_{i}\sum_{c}q(t_i=c)logq(t_i=c)\\&space;&=E_qlogp(X,T|\theta)&space;&plus;&space;const&space;\end{align*}" title="\begin{align*} L(\theta,q)&=\sum_{i}\sum_{c}q(t_i=c)log\frac{p(x_i,t_i=c|\theta)}{q(t_i=c)}\\ &=\sum_{i}\sum_{c}q(t_i=c)logp(x_i,t_i=c|\theta) - \sum_{i}\sum_{c}q(t_i=c)logq(t_i=c)\\ &=E_qlogp(X,T|\theta) + const \end{align*}" /></a>
<br> As you can see, $$E_q\;log\;p(X,T\mid \theta)$$ is (usually) a concave function with respect to theta, which is easy to optimize!
<br>
<br>

## (3) Understanding EM-algorithm Visually

To write $$p$$  in general form, 

- $$lnp(X|θ)=L(q,θ)+KL(q∥p)ln⁡p(X|θ)=L(q,θ)+KL(q‖p)$$



### E step

- Make $$KL(q\mid \mid p)$$ = 0, that is , pull up the blue line up to the red line!



<img src="http://norman3.github.io/prml/images/Figure9.12.png" width="350" /> </br>



### M step

- fix $$q$$ and find $$\theta^{new}$$
- that is, make the red line higher!

<img src="http://norman3.github.io/prml/images/Figure9.13.png" width="300" /> </br>



Repeat this E & M step!



## (4) Summary of EM algorithm 
[1] method for training Latent Variable Models 
<br>

[2] Handles missing data 
<br>

[3] sequence of simple tasks instead of one hard task 
<br>

[4] guarantees to converge ( local or global ) 
<br>

[5] helps with complicated parameter constraints
<br>

[6] E & M step <br>

In E-step, we maximize the lower bound with respect to q, and in the M-step, we maximize the lower bound with respect to theta. The mathematical expression will be like the below.
<br>
<br>

- E step : <a href="https://www.codecogs.com/eqnedit.php?latex=q^{k&plus;1}(t_i)&space;=&space;p(t_i|x_i,\theta^k)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q^{k&plus;1}(t_i)&space;=&space;p(t_i|x_i,\theta^k)" title="q^{k+1}(t_i) = p(t_i|x_i,\theta^k)" /></a>
<br>

- M step : <a href="https://www.codecogs.com/eqnedit.php?latex=\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}E_{q^{k&plus;1}}\;logp(X,T|\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta^{k&plus;1}&space;=&space;\underset{\theta}{argmax}E_{q^{k&plus;1}}\;logp(X,T|\theta)" title="\theta^{k+1} = \underset{\theta}{argmax}E_{q^{k+1}}\;logp(X,T|\theta)" /></a>
