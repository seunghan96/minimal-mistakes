---
title: 14.(nlp) ELMo (Embeddings from Language Model)
categories: [DL,NLP]
tags: [Deep Learning, NLP]
excerpt: GloVe
---

# ELMo (Embeddings from Language Model)

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

( 참고 : "딥러닝을 이용한 자연어 처리 입문" (https://wikidocs.net/book/2155) )

<br>

# 1. Introduction

ELMo는 **"문맥"을 고려한 word embedding** 방법이다. 

예를 들어, "배가 고프다"와, "배를 타고 여행을 가다"에서의 "배"는 서로 다른 뜻을 가진다. 하지만, word2vec이나 GloVe는 이와 같은 차이를 구분하지 못한다. 하지만, ELMo는 **문맥을 고려**하여 embedding을 하여, 보다 나은 성능을 보여준다.



# 2. bi-RNN vs biLM of ELMO

ELMo는 순방향/역방향 LM(언어 모델)을 둘 다 사용한 **biLM (Bidirectional Languange Model)**이다. ( 아래의 그림 참고 )

<img src="https://wikidocs.net/images/page/33930/deepbilm.PNG" width="300" />.



위의 그림은 마치 이전에 배웠단 bidirectional RNN과 유사해보이지만, ELMo의 biLM은 이와 약간 다르다.

- **bidirectional RNN** : forward & backward RNN의 hidden state를 concatenate한 이후로 다음 층의 입력으로 사용
- **biLM of ELMo** : forward & Backward RNN 각각의 hidden state만을 다음 층의 입력으로 사용

그림을 참고하면 이해하기 쉽다.

<img src="https://wikidocs.net/images/page/33930/playwordvector.PNG" width="500" />.



# 3. biLM (Bidirectional Language Model)

**Step 1) 각 layer별로, forward LM과 backward LM에서의 출력값들을 서로 concatenate한다.**

<img src="https://wikidocs.net/images/page/33930/concatenate.PNG" width="200" />.

<br>

**Step 2) 각 layer별로, weight를 부여한다.**

<img src="https://wikidocs.net/images/page/33930/weight.PNG" width="250" />.

<br>

**Step 3)위의 weight를 바탕으로 weighted sum을 구한다.**

<img src="https://wikidocs.net/images/page/33930/weightedsum.PNG" width="350" />.

<br>

**Step 4) scalar parameter를 곱한다.**

<img src="https://wikidocs.net/images/page/33930/scalarparameter.PNG" width="350" />.

- 위의 Step 4)를 통해서 나오게 된 것을 **ELMo representation**이라고 한다.

<br>

# 4. Summary

위의 biLM에 대한 설명으로, ELMo에 대한 이해는 사실상 모두 끝났다.

<br>

우리에게 어떠한 text가 주어졌을 때, 아래의 2가지를 서로 concatenate한다

- 1) biLM를 거쳐서 생성된 **ELMo representation**
- 2) 기존의 방법 (ex.GloVe, word2vec 등)을 통해서 생성된 **embedding vector**



<img src="https://wikidocs.net/images/page/33930/elmorepresentation.PNG" width="350" />.









