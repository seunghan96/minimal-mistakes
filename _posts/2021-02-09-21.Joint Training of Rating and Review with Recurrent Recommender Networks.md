---
title: 21.[paper review] Joint Training of Rating and Review with Recurrent Recommender Networks
categories: [RS]
tags: 
excerpt: Joint Training of Rating and Review with Recurrent Recommender Networks
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# [ Recommender System ]

# 21. Joint Training of Rating and Review with Recurrent Recommender Networks

( 참고 : Fastcampus 추천시스템 강의 )

<br>

## 1. Abstract

- **Neural Network 모델**

- rating과 **text review를 같이 사용**하여 성능 향상!

- RNN 구조를 통해, user와 item의 다양한 component를 얻어냄

  ( RNN 구조이기 때문에 temporal pattern 또한 당연히 잡아냄 )



## 2. Introduction

이전의 알고리즘들 :

- **RRN (Reccurent Recommender Network)** :
  - user & item의 변화를 파악 O
  - but review의 시간적인 변화 capture X
- NLP의 발달에 비해, 이를 사용한 RS는 이에 비해 뒤떨어짐
- RS에서 review를 사용하기 어려운 이유 : unstructured & diverse



Contribution

- (1) Joint Generative Model : REVIEW + RATING
- (2) NON-linear nonparameteric review model
  - 유저와 영화의 state dynamics를 학습 ( = 시간의 변화에 따른 리뷰의 변화 파악 가능 )
- (3) IMDB에 좋은 성능



## 3. Recurrent Recommender Network

![figure2](/assets/img/recsys/21-1.png)

- 왼쪽 ) time INDEPENDENT
- 오른쪽 ) **time DEPENDENT**



![figure2](/assets/img/recsys/21-2.png)

Reccurent Recommender Networks

- 유저에 대한 **state evolution**은, 유저가 이전에 rating을 준 영화와 관련

- **movie의 parameter** : 과거에 그 영화가 어땠는지 시간에 따라 다름!



## 4. Model

![figure2](/assets/img/recsys/21-3.png)

왼쪽) Rating 데이터

오른쪽) Review 데이터로



[ Details ]

1. Dynamic User & Movie State

- 과거 rating을 input으로 **state** update 



2. Rating Emissions

- 시간에 따라 변하는 $$u_{it}$$, $$m_{jt}$$ 를, 고정된 $$u_i$$,$$m_j$$로 보완할 수 있음

  ( ex. 장기적 선호 등, 시간에 따라 변하지 않는 요소등 )

- 아래와 같이 decompose하여 표현 가능

  $$r_{i j}=f\left(u_{i t}, m_{j t}, u_{i}, m_{j}\right):=\left\langle\widetilde{u_{i t}}, \widetilde{m_{j t}}\right\rangle+\left\langle u_{i \mid}+m_{j}\right\rangle$$



3. Review Text Model

- character 단위 LSTM
- 유저 & 아ㅏ이템의 latent state 반영
- Bottle Neck 층 $$x_{\text {joint }, i j}\left(=x_{i j}\right)$$에서 user/movie의 정적&동적 정보 합침

![figure2](/assets/img/recsys/21-4.png)



Loss Function : $$L:=\sum_{(i, j) \in D_{\text {train }}}\left[\left(\hat{r}_{i j}(\theta)-r_{i j}\right)^{2}-\lambda \sum_{k=1}^{n_{i j}} \log \left(\operatorname{Pr}\left(o_{i j, k} \mid \theta\right)\right)\right]$$

- $$n_{ij}$$ : 유저 $$i$$가 영화 $$j$$에 쓴 review의 글자 수
- $$\lambda$$ : rating & review의 가중치




